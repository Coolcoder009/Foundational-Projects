{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Text Generation with Markvo chains**"
      ],
      "metadata": {
        "id": "wHbK_OfEWhcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "EFBGXTWjWlRS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Getting data by hitting the req**"
      ],
      "metadata": {
        "id": "9salHkEwlgAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_url(url,name):\n",
        "  !wget {url}\n",
        "  response = requests.get(url)\n",
        "  if response.status_code == 200:\n",
        "    with open(name,'wb') as file:\n",
        "      file.write(response.content)"
      ],
      "metadata": {
        "id": "mD_6FgyxWr6p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_url(\"http://www.textfiles.com/stories/timem.hac\",\"Data1\")\n",
        "get_url(\"http://www.textfiles.com/stories/3gables.txt\",\"Data2\")\n",
        "get_url(\"http://www.textfiles.com/stories/fgoose.txt\", \"Data3\")\n",
        "get_url(\"http://www.textfiles.com/stories/hitch3.txt\", \"Data4\")\n",
        "get_url(\"http://www.gutenberg.org/files/1342/1342-0.txt\", \"Data5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VjxIKC_sKI9",
        "outputId": "6b0016e4-4849-4015-dd44-bd4d8c0ea32f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-22 11:35:32--  http://www.textfiles.com/stories/timem.hac\n",
            "Resolving www.textfiles.com (www.textfiles.com)... 208.86.224.90\n",
            "Connecting to www.textfiles.com (www.textfiles.com)|208.86.224.90|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 185134 (181K)\n",
            "Saving to: ‘timem.hac’\n",
            "\n",
            "timem.hac           100%[===================>] 180.79K   610KB/s    in 0.3s    \n",
            "\n",
            "2025-05-22 11:35:32 (610 KB/s) - ‘timem.hac’ saved [185134/185134]\n",
            "\n",
            "--2025-05-22 11:35:33--  http://www.textfiles.com/stories/3gables.txt\n",
            "Resolving www.textfiles.com (www.textfiles.com)... 208.86.224.90\n",
            "Connecting to www.textfiles.com (www.textfiles.com)|208.86.224.90|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33985 (33K) [text/plain]\n",
            "Saving to: ‘3gables.txt’\n",
            "\n",
            "3gables.txt         100%[===================>]  33.19K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-05-22 11:35:33 (336 KB/s) - ‘3gables.txt’ saved [33985/33985]\n",
            "\n",
            "--2025-05-22 11:35:33--  http://www.textfiles.com/stories/fgoose.txt\n",
            "Resolving www.textfiles.com (www.textfiles.com)... 208.86.224.90\n",
            "Connecting to www.textfiles.com (www.textfiles.com)|208.86.224.90|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75471 (74K) [text/plain]\n",
            "Saving to: ‘fgoose.txt’\n",
            "\n",
            "fgoose.txt          100%[===================>]  73.70K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-05-22 11:35:34 (495 KB/s) - ‘fgoose.txt’ saved [75471/75471]\n",
            "\n",
            "--2025-05-22 11:35:34--  http://www.textfiles.com/stories/hitch3.txt\n",
            "Resolving www.textfiles.com (www.textfiles.com)... 208.86.224.90\n",
            "Connecting to www.textfiles.com (www.textfiles.com)|208.86.224.90|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 327595 (320K) [text/plain]\n",
            "Saving to: ‘hitch3.txt’\n",
            "\n",
            "hitch3.txt          100%[===================>] 319.92K   795KB/s    in 0.4s    \n",
            "\n",
            "2025-05-22 11:35:34 (795 KB/s) - ‘hitch3.txt’ saved [327595/327595]\n",
            "\n",
            "--2025-05-22 11:35:35--  http://www.gutenberg.org/files/1342/1342-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.gutenberg.org/files/1342/1342-0.txt [following]\n",
            "--2025-05-22 11:35:35--  https://www.gutenberg.org/files/1342/1342-0.txt\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 752575 (735K) [text/plain]\n",
            "Saving to: ‘1342-0.txt’\n",
            "\n",
            "1342-0.txt          100%[===================>] 734.94K  2.55MB/s    in 0.3s    \n",
            "\n",
            "2025-05-22 11:35:36 (2.55 MB/s) - ‘1342-0.txt’ saved [752575/752575]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lines(path):\n",
        "    txt = []\n",
        "    with open(path, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line != '':\n",
        "                txt.append(line)\n",
        "    return txt\n",
        "\n",
        "# Combine all data files\n",
        "corpus = []\n",
        "for i in range(1, 6):  # for Data1 to Data4\n",
        "    file_path = f\"/content/Data{i}\"\n",
        "    lines = get_lines(file_path)\n",
        "    corpus.extend(lines)  # appending the lines to the main corpus\n",
        "\n",
        "print(f\"Total lines in corpus: {len(corpus)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ZxGZ4fsb-g",
        "outputId": "83078cdb-4b28-4e1c-a9a2-7a7778ad9402"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total lines in corpus: 22355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_and_count_words(corpus):\n",
        "    word_count = 0\n",
        "    cleaned_text = []\n",
        "    for line in corpus:\n",
        "        line = line.strip()\n",
        "        if line == '----------':\n",
        "            break\n",
        "        if line != '':\n",
        "            # Tokenize using regex\n",
        "            words = re.findall(r'\\b\\w+\\b', line)\n",
        "            word_count += len(words)\n",
        "            cleaned_text.extend(words)\n",
        "\n",
        "    return cleaned_text  # List of words\n",
        "\n",
        "# Now pass the previously built corpus\n",
        "cleaned_text = clean_and_count_words(corpus)\n",
        "print(\"Number of words =\", len(cleaned_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDbGdJ9oy6mj",
        "outputId": "eb029a98-77cc-4449-a793-a5b02f670d7f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words = 235391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Unigram**"
      ],
      "metadata": {
        "id": "ZgWjxf3jyrUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def build_markov_chain(words):\n",
        "    markov_chain = defaultdict(list)\n",
        "    for i in range(len(words) - 1):\n",
        "        curr_word = words[i]\n",
        "        next_word = words[i + 1]\n",
        "        markov_chain[curr_word].append(next_word)\n",
        "    return markov_chain\n",
        "\n",
        "\n",
        "def generate_unigram_text(chain, length=20):\n",
        "    word = random.choice(list(chain.keys()))  # random start\n",
        "    output = [word]\n",
        "\n",
        "    for _ in range(length - 1):\n",
        "        next_words = chain.get(word)\n",
        "        if not next_words:\n",
        "            break  # no known next word\n",
        "        word = random.choice(next_words)\n",
        "        output.append(word)\n",
        "\n",
        "    return ' '.join(output)"
      ],
      "metadata": {
        "id": "JK-gAUaq0z1a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bigram**"
      ],
      "metadata": {
        "id": "3UhkU2Um0i9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bigram_chain(words):\n",
        "    markov_chain = defaultdict(list)\n",
        "    for i in range(len(words) - 2):\n",
        "        key = (words[i], words[i + 1])        # Bigram as key\n",
        "        next_word = words[i + 2]              # Word that follows\n",
        "        markov_chain[key].append(next_word)\n",
        "    return markov_chain\n",
        "\n",
        "def generate_bigram_text(chain, length=20):\n",
        "    current_pair = random.choice(list(chain.keys()))  # random bigram (tuple)\n",
        "    output = [current_pair[0], current_pair[1]]       # start with both words\n",
        "\n",
        "    for _ in range(length - 2):  # already have 2 words\n",
        "        next_words = chain.get(current_pair)\n",
        "        if not next_words:\n",
        "            break\n",
        "        next_word = random.choice(next_words)\n",
        "        output.append(next_word)\n",
        "        # move the window: (second word of current pair, next word)\n",
        "        current_pair = (current_pair[1], next_word)\n",
        "\n",
        "    return ' '.join(output)"
      ],
      "metadata": {
        "id": "WqvfPar50iHA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Trigram**"
      ],
      "metadata": {
        "id": "8ydU6JhC6A4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_trigram_chain(words):\n",
        "    markov_chain = defaultdict(list)\n",
        "    for i in range(len(words) - 3):\n",
        "        key = (words[i], words[i + 1], words[i + 2])  # 3-word tuple as key\n",
        "        next_word = words[i + 3]                       # word that follows\n",
        "        markov_chain[key].append(next_word)\n",
        "    return markov_chain\n",
        "\n",
        "def generate_trigram_text(chain, length=20):\n",
        "    current_triplet = random.choice(list(chain.keys()))  # random trigram key\n",
        "    output = [current_triplet[0], current_triplet[1], current_triplet[2]]  # start words\n",
        "\n",
        "    for _ in range(length - 3):\n",
        "        next_words = chain.get(current_triplet)\n",
        "        if not next_words:\n",
        "            break\n",
        "        next_word = random.choice(next_words)\n",
        "        output.append(next_word)\n",
        "        # Slide the window: drop first word, add next_word\n",
        "        current_triplet = (current_triplet[1], current_triplet[2], next_word)\n",
        "\n",
        "    return ' '.join(output)"
      ],
      "metadata": {
        "id": "NNB5AYEt3PC1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = input(\"Enter 1 for unigram or 2 for Bigram or 3 for Trigram:\")\n",
        "\n",
        "if n == '1':\n",
        "  chain = build_markov_chain(cleaned_text)\n",
        "  generated = generate_unigram_text(chain, length=100)\n",
        "  with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(generated)\n",
        "elif n == '2':\n",
        "  chain = build_bigram_chain(cleaned_text)\n",
        "  generated = generate_bigram_text(chain, length=100)\n",
        "  with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(generated)\n",
        "elif n == '3':\n",
        "  chain = build_trigram_chain(cleaned_text)\n",
        "  generated = generate_trigram_text(chain, length=100)\n",
        "  with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(generated)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iypgpPVJ1xH2",
        "outputId": "a38dd88f-7e9d-4064-a681-ebc92745bfe8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter 1 for unigram or 2 for Bigram or 3 for Trigram:3\n"
          ]
        }
      ]
    }
  ]
}